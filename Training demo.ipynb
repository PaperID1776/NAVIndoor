{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abcbcb08-62fe-4691-84ad-b42bd981fe76",
   "metadata": {},
   "source": [
    "# Imports and environment loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51a04ab9-d598-4ff0-8271-f594d9b29477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UnityMemory] Configuration Parameters - Can be set up in boot.config\n",
      "    \"memorysetup-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-cache-allocator-block-size=4194304\"\n",
      "    \"memorysetup-typetree-allocator-block-size=2097152\"\n",
      "    \"memorysetup-profiler-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-profiler-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-profiler-allocator-block-size=16777216\"\n",
      "    \"memorysetup-profiler-editor-allocator-block-size=1048576\"\n",
      "    \"memorysetup-temp-allocator-size-main=4194304\"\n",
      "    \"memorysetup-job-temp-allocator-block-size=2097152\"\n",
      "    \"memorysetup-job-temp-allocator-block-size-background=1048576\"\n",
      "    \"memorysetup-job-temp-allocator-reduction-small-platforms=262144\"\n",
      "    \"memorysetup-allocator-temp-initial-block-size-main=262144\"\n",
      "    \"memorysetup-allocator-temp-initial-block-size-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-background-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-job-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-preload-manager=262144\"\n",
      "    \"memorysetup-temp-allocator-size-nav-mesh-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-audio-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-cloud-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-gfx=262144\"\n"
     ]
    }
   ],
   "source": [
    "from utils.model import MNmodelPartAM_Dueling\n",
    "import pickle\n",
    "import torch\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from utils.learner import Segmenter, RLLearner\n",
    "from utils.env_utils import load_env\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_build = 'NAVIndoor/maze' #environment path\n",
    "env, behavior_name,channel_env = load_env(train_build,10,0,0,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef45c02-527e-468f-9b23-c1dc119495a4",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01eac33c-dd90-4d55-b86b-38bbc8942491",
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = {0:[1,0]\n",
    "     ,1:[0,1]\n",
    "     ,2:[0,-1]\n",
    "     ,3:[-1,0]\n",
    "     #,4:[1,1]\n",
    "     #,5:[1,-1]\n",
    "     #,6:[-1,1]\n",
    "     #,7:[-1,-1]\n",
    "     #,8:[0,0]\n",
    "     } #action mapper. Includes 9 possibilities with combinations for moving (first parameter : 1 = forward, -1 = backward) and rotation (second parameter : -1 = left, 1 = right). On our experiments we only use 4.\n",
    "output_classes = len(ac)\n",
    "\n",
    "\n",
    "erase = False\n",
    "budget = 100000 \n",
    "n_frames = 3\n",
    "\n",
    "scale = 3 #model size\n",
    "aes = 20 #action embedding space length\n",
    "am = 20 #action memory buffer length \n",
    "ahes = 150 #action memory representation length\n",
    "\n",
    "\n",
    "buffer_size = 12000 #replay buffer size. Big sizes may not fill in small memory devices.\n",
    "gamma = 0.97\n",
    "train_every = 5 #backward frequency\n",
    "\n",
    "\n",
    "\n",
    "update_type = 'hard' #update type for Q theta - ('hard' or 'soft')\n",
    "tau = 0.01 # soft update parameter if update_type = 'e\n",
    "update_every = 50 #update frequency of Q theta - if update_type = 'hard'\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "batch_size = 128\n",
    "\n",
    "episode_duration = 400\n",
    "epsilon_decrease = int(budget/3)\n",
    "epsilon_min = 0.15\n",
    "\n",
    "#model = MNmodelPartAM_Dueling(scale=scale,output=output_classes,dropout=0,n_actions = output_classes,am = am,aes = aes, ahes = ahes,n_frames = n_frames)\n",
    "#target_model = MNmodelPartAM_Dueling(scale=scale,output=output_classes,dropout=0, n_actions = output_classes,am = am, aes = aes, ahes = ahes, n_frames = n_frames)\n",
    "\n",
    "env_settings = {\"coin_proba\":1, #parameters for the environments. \n",
    " \"increase_obstacle_proba\":1, #Linear increase in obstacle proportion until max_obstacle_proba is reached\n",
    " \"move_speed\":[1,1], #Movement speed\n",
    " \"turn_speed\":[150,150], #Rotation speed\n",
    " \"momentum\":[0,0], #Inertial momentum\n",
    " \"decrease_reward_on_stay\":0, #decrease reward when OnStayCollided method is called\n",
    " \"coin_visible\":1, #Coins visibility\n",
    " \"max_obstacle_proba\":0.3} #Obstacle proportion\n",
    "\n",
    "\n",
    "name = '3_1_1_1-1_0_floor_dueling'\n",
    "\n",
    "\n",
    "\n",
    "#model =  SFO_model(output_classes=output_classes,scale_fl = scale, model_class = MNmodelPart,dropout=0)\n",
    "#target_model = SFO_model(output_classes=output_classes,scale_fl = scale, model_class = MNmodelPart,dropout=0)\n",
    "\n",
    "model = MNmodelPartAM_Dueling(scale=scale,output=output_classes,dropout=0,n_actions = output_classes,am = am,aes = aes, ahes = ahes,n_frames=3)\n",
    "target_model = MNmodelPartAM_Dueling(scale=scale,output=output_classes,dropout=0, n_actions = output_classes,am = am, aes = aes, ahes = ahes,n_frames=3)\n",
    "\n",
    "\n",
    "\n",
    "Learner = RLLearner(env=env,\n",
    "                    model=model,\n",
    "                    target_model=target_model,\n",
    "                    learning_rate = learning_rate,\n",
    "                    update_every = update_every, \n",
    "                    buffer_size= buffer_size, \n",
    "                    gamma = gamma, \n",
    "                    batch_size = batch_size,\n",
    "                    epsilon_decrease=epsilon_decrease,\n",
    "                    episode_duration = episode_duration,\n",
    "                    action_mapper = ac,\n",
    "                    segmenter = Segmenter(True), #Segmenter argument is ground segmentation (with value 0.5)\n",
    "                    train_every = train_every,\n",
    "                    device = device,\n",
    "                    do_clip = 0, #save a clip after each episode.\n",
    "                    epsilon_min = epsilon_min,\n",
    "                    action_memory = am,\n",
    "                   update_type = update_type,\n",
    "                   tau= tau,\n",
    "                   using_seg_input=True,\n",
    "                   n_frames = n_frames,\n",
    "                   channel_env = channel_env,\n",
    "                   budget = budget,\n",
    "                   env_settings = env_settings,\n",
    "                   eval_n = 2) #number of episodes used for evaluation.\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d0e314-0bcd-4395-b876-b63e08b94417",
   "metadata": {},
   "outputs": [],
   "source": [
    "Learner.train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48745165-24f2-41da-964d-91b321394ae4",
   "metadata": {},
   "source": [
    "# Save model and reward values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002487d9-3687-465d-a17e-1a57cdb12d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Learner.rewards_eval,'r')\n",
    "with open('graphs_v3/'+name+'.pickle', 'wb') as f:\n",
    "    pickle.dump(Learner.rewards_eval,f)\n",
    "plt.savefig('graphs_v3/'+name+'.png',dpi=300)\n",
    "print('graphs_v3/'+name+'.png')\n",
    "plt.close()\n",
    "torch.save(Learner.model.state_dict(), 'graphs_v3/'+name+'.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afde4a45-0061-44c4-afc0-b93c1b0570f9",
   "metadata": {},
   "source": [
    "# Clip a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9407430d-dd84-4096-bafb-1c66b86656a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 1000/1000 [00:00<00:00, 21285.48it/s]\n"
     ]
    }
   ],
   "source": [
    "frames = Learner.clip(1000)\n",
    "video = cv2.VideoWriter('video_episode.avi',cv2.VideoWriter_fourcc(*'XVID'),15, (128,128)) #path, encoding, frames per second, image size\n",
    "for image in tqdm(frames):\n",
    "    video.write(cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "video.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
